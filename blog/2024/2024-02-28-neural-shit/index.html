<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="the-neural-map">The Neural Map</h2> <p>Our sense of navigation is not something we tend to consider too deeply in our day-to-day lives. Nevertheless, we somehow have a subconscious knowledge of were we are in the world and where we are going. We use it everywhere - to walk home, to go to the grocery store, to walk to the bathroom in the middle of the night.</p> <p>How we navigate is largely dependent on what information is available to us. The brain is complex and uses a variety of strategies to determine our position, relative to other landmarks and to start or goal locations. Among those is beaconing, a strategy where we use a distant object to navigate to - say, “Hey, there’s a neon sign here saying ‘Pub’” - that’s probably the entrance to the pub. But what if you don’t have those clues?</p> <p>This is where path integration comes in.</p> <hr> <h2 id="path-integration">Path Integration</h2> <p>Say you’re out on a hike with your friends. You’re full of energy during the day and make plenty of detours before you get to the campsite and settle in for a restful night, listening to the soothing patter of rain on the tent. Oh no! It’s 2am and you’re woken up in what an optimist would call a ‘puddle’, and anyone else might label ‘a decidedly sizable body of water’.</p> <p><em>So much for the guy on Facebook Marketplace promising that the tent was waterproof.</em></p> <p>You and your friend make the decision to trek back to the car park. You wish one of you had brought a headlamp at least - you can’t use any landmarks to navigate. Despite that, you somehow manage to make it back in one piece, going straight from the campsite to the carpark without any of the diversions you had undertaken on the way there. <em>How?</em></p> <p><strong>INSERT PHASER GAME</strong></p> <p>Two types of sensory information are required to update where we think we are: <em>Allothetic information</em> we get from the outside environment, like that ‘Pub’ sign. <em>Idiothetic information</em> is generated by the body itself. For example, the brain signals responsible for walking to the pub also provide us with information about how far we’ve walked so far. Path integration uses these idiothetic cues to transverse the mental map in our head. For example, a mouse that is foraging and takes a long, winding trajectory towards its goal will have ‘calculated’ its displacement from its nest and can make a beeline safely back if it suddenly runs into a fox.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/images/mouse_integration-480.webp 480w,/assets/img/images/mouse_integration-800.webp 800w,/assets/img/images/mouse_integration-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/images/mouse_integration.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="mouse integration" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Studying path integration is complicated by the fact that it’s only one part of the mechanism behind navigation. It’s an error-prone system, and so it works in combination with other information to create a path - for example, a mouse might use remembered landmarks, olfaction and even way-marking to navigate through an environment. Studying the neurons specifically involved in path integration therefore requires us to remove all other possibilities but using path integration. How do we do <em>that?</em></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/images/pi_exp_p1-480.webp 480w,/assets/img/images/pi_exp_p1-800.webp 800w,/assets/img/images/pi_exp_p1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/images/pi_exp_p1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>One way of studying path integration is using virtual reality. Mice run through a VR corridor on a treadmill until there’s a visual cue. If they stop at the visual cue, they get a treat. After a few repetitions, the visual cue is removed - yet the mice still stop in the place where the visual cue <em>would have been</em>. If there are no external cues for the mice to see, how do they know when to stop?</p> <p>The mice can’t use other navigational strategies, such as beaconing, because there’s no allothetic cues, so they’re left with path integration. They might have remembered the time it took to run to the reward zone - but when the speed of the treadmill was changed, the mice didn’t overshoot the reward zone, despite running faster. This implies they weren’t measuring the time, but were instead getting their information from a collection of self-motion cues. This includes proprioception (the sense of your self-position and self-movement) along with the vestibular system (your inner ear, which provides a sense of balance and awareness of our head and body in space) and motor efference. Over longer distances, the accuracy of this system drops without external input such as landmarks, as small errors start to accumulate and the mice start to stop further away from the reward zone.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/images/pi_exp_2-480.webp 480w,/assets/img/images/pi_exp_2-800.webp 800w,/assets/img/images/pi_exp_2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/images/pi_exp_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="pi 1" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>&lt;/div&gt;&gt;</p> <h2 id="cell-types">Cell types</h2> <p>Path integration is just one of the many navigational strategies we want to study to understand the basis of the neural map. There are many specialised cell types involved in navigation. For the purpose of this website, let’s focus on three: place cells, grid cells, and head direction cells.</p> <div class="image-container"> <img class="comic" src="./images/cell_types.png" alt="cell types"> <div class="hover-textbox"> **Grid cells** are place-modulated neurons located primarily in the entorhinal cortex that fire periodically in space, mapping a triangular grid across an environment. As an animal moves through space, grid cells fire to create hexagonal patterns that allow us to map this space. Again, a population of grid cells alone can encode a spatial map **Place cells** located in the hippocampus, fire when an animal enters a specific location in space. A population of place cells alone can encode a spatial map. **Head direction cells** are primarily found in the postsubiculum, and provide directional information by preferentially firing in specific directions. A population of head direction cells can encode which direction you are facing in your spatial map. These cells potentially have uses outside of encoding physical space - their coding mechanism may be used for more general problem sets, such as cognitive mapping. Cognitive mapping refers to swapping out the three-dimensional world we interact with for a different, continuous dimension that represents an abstract concept. The same way we might encode the map of our room, we might use the hexagonal-firing properties of grid cells to represent, for example, conceptual spaces, such as hierarchically organizing ideas within our brain, or recording temporal sequences of events. </div> </div> <p>&lt;/div&gt;</p> <hr> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr> </body></html>